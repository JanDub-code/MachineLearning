{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Price Prediction Model Tuning\n",
                "\n",
                "This notebook focuses on tuning the final model used to predict stock prices.\n",
                "\n",
                "## Goal\n",
                "Find the best hyperparameters using **Grid Search** and **TimeSeriesSplit Cross Validation**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Complete Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = \"../data/complete\"\n",
                "df = pd.read_csv(os.path.join(DATA_DIR, \"all_sectors_complete_10y.csv\"))\n",
                "df['date'] = pd.to_datetime(df['date'])\n",
                "df = df.sort_values(['ticker', 'date'])\n",
                "\n",
                "print(f\"Total samples: {len(df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering (Simplified)\n",
                "Create a target variable (e.g., Next Month Price)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Shift close price to create target\n",
                "df['target'] = df.groupby('ticker')['close'].shift(-1) # Predict next month\n",
                "data = df.dropna()\n",
                "\n",
                "features = ['close', 'volume', 'rsi_14', 'macd', 'PE', 'ROE', 'Debt_to_Equity']\n",
                "X = data[features]\n",
                "y = data['target']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Time Series Cross Validation\n",
                "Standard K-Fold is NOT suitable for time series data because it shuffles data, causing data leakage (training on future data). We must use `TimeSeriesSplit`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pipeline\n",
                "pipeline = Pipeline([\n",
                "    ('scaler', StandardScaler()),\n",
                "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
                "])\n",
                "\n",
                "# Parameter Grid\n",
                "param_grid = {\n",
                "    'regressor__n_estimators': [100, 200],\n",
                "    'regressor__learning_rate': [0.01, 0.1],\n",
                "    'regressor__max_depth': [3, 5]\n",
                "}\n",
                "\n",
                "# Time Series Split\n",
                "tscv = TimeSeriesSplit(n_splits=5)\n",
                "\n",
                "# Grid Search\n",
                "grid_search = GridSearchCV(\n",
                "    pipeline,\n",
                "    param_grid,\n",
                "    cv=tscv,\n",
                "    scoring='neg_mean_absolute_error',\n",
                "    n_jobs=-1,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"Starting Grid Search (TimeSeriesSplit)...\")\n",
                "grid_search.fit(X, y)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Results Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
                "print(f\"Best MAE: {-grid_search.best_score_:.4f}\")\n",
                "\n",
                "# Visualize CV Results\n",
                "results_df = pd.DataFrame(grid_search.cv_results_)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(data=results_df, x='param_regressor__learning_rate', y='mean_test_score', hue='param_regressor__max_depth')\n",
                "plt.title('Grid Search Results: Learning Rate vs Negative MAE')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

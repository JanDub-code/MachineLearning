{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa50147",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Teoretick√Ω √övod\n",
    "\n",
    "### 1.1 Proƒç Random Forest pro Imputaci?\n",
    "\n",
    "**Random Forest** je ensemble metoda kombinuj√≠c√≠ rozhodovac√≠ stromy:\n",
    "\n",
    "$$\\hat{y} = \\frac{1}{B}\\sum_{b=1}^{B} T_b(x)$$\n",
    "\n",
    "kde:\n",
    "- $B$ = poƒçet strom≈Ø (n_estimators)\n",
    "- $T_b(x)$ = predikce b-t√©ho stromu\n",
    "\n",
    "#### V√Ωhody pro imputaci:\n",
    "\n",
    "| Vlastnost | Proƒç je d≈Øle≈æit√° |\n",
    "|-----------|------------------|\n",
    "| **Neline√°rn√≠ vztahy** | Zachycuje komplexn√≠ z√°vislosti mezi OHLCV a fundamenty |\n",
    "| **Robustnost v≈Øƒçi outlier≈Øm** | Finanƒçn√≠ data obsahuj√≠ extr√©my (NVDA +200%) |\n",
    "| **Multi-output podpora** | Predikuje v≈°ech 14 metrik najednou |\n",
    "| **Feature importance** | Interpretovatelnost - kter√© features jsou kl√≠ƒçov√© |\n",
    "| **≈Ω√°dn√° normalizace** | Stromy nepot≈ôebuj√≠ ≈°k√°lov√°n√≠ dat |\n",
    "\n",
    "### 1.2 Multi-Output Regrese\n",
    "\n",
    "M√≠sto 14 samostatn√Ωch model≈Ø tr√©nujeme jeden **MultiOutputRegressor**:\n",
    "\n",
    "$$f: \\mathbb{R}^{18} \\rightarrow \\mathbb{R}^{14}$$\n",
    "\n",
    "**Vstup (18 features):**\n",
    "- OHLCV: open, high, low, close, volume\n",
    "- Technick√©: returns, volatility, rsi, macd, sma, ema, ...\n",
    "\n",
    "**V√Ωstup (14 targets):**\n",
    "- Valuace: PE, PB, PS, EV_EBITDA\n",
    "- Profitabilita: ROE, ROA, mar≈æe (3)\n",
    "- Zdrav√≠: Debt/Equity, Current/Quick Ratio (3)\n",
    "- R≈Øst: Revenue/Earnings Growth (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e91ae",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Setup Prost≈ôed√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdf07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace (pro Colab)\n",
    "!pip install pandas numpy scikit-learn joblib matplotlib seaborn tqdm -q\n",
    "\n",
    "print(\"‚úì Knihovny nainstalov√°ny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import knihoven\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Knihovny naƒçteny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ôipojen√≠ Google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DRIVE_PATH = '/content/drive/MyDrive/MachineLearning'\n",
    "    RUNNING_ON_COLAB = True\n",
    "    print(f\"‚úì Google Drive p≈ôipojen: {DRIVE_PATH}\")\n",
    "except:\n",
    "    DRIVE_PATH = '.'\n",
    "    RUNNING_ON_COLAB = False\n",
    "    print(\"‚ÑπÔ∏è Lok√°ln√≠ prost≈ôed√≠\")\n",
    "\n",
    "# Cesty\n",
    "DATA_PATH = f\"{DRIVE_PATH}/data\"\n",
    "MODEL_PATH = f\"{DRIVE_PATH}/models\"\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b26381",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Naƒçten√≠ Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7274e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ OHLCV dat z Notebooku 01\n",
    "ohlcv_path = f\"{DATA_PATH}/ohlcv/all_sectors_ohlcv_10y.csv\"\n",
    "ohlcv_df = pd.read_csv(ohlcv_path, parse_dates=['date'])\n",
    "\n",
    "print(f\"üìà OHLCV Data:\")\n",
    "print(f\"   Z√°znam≈Ø: {len(ohlcv_df):,}\")\n",
    "print(f\"   Ticker≈Ø: {ohlcv_df['ticker'].nunique()}\")\n",
    "print(f\"   Obdob√≠: {ohlcv_df['date'].min().strftime('%Y-%m')} ‚Üí {ohlcv_df['date'].max().strftime('%Y-%m')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ fundament√°ln√≠ch dat\n",
    "fund_path = f\"{DATA_PATH}/fundamentals/all_sectors_fundamentals.csv\"\n",
    "fundamentals_df = pd.read_csv(fund_path, parse_dates=['date'])\n",
    "\n",
    "print(f\"\\nüìä Fundament√°ln√≠ Data:\")\n",
    "print(f\"   Z√°znam≈Ø: {len(fundamentals_df)}\")\n",
    "print(f\"   Ticker≈Ø: {fundamentals_df['ticker'].nunique()}\")\n",
    "\n",
    "# Zobrazen√≠ prvn√≠ch z√°znam≈Ø\n",
    "display(fundamentals_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd5135e",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. P≈ô√≠prava Tr√©novac√≠ch Dat\n",
    "\n",
    "### 4.1 Strategie\n",
    "\n",
    "1. **Merge** OHLCV dat s fundamenty podle tickeru\n",
    "2. **Forward-fill** fundament≈Ø pro vytvo≈ôen√≠ vƒõt≈°√≠ho datasetu\n",
    "3. **V√Ωbƒõr features** (OHLCV + technick√©) a **targets** (14 fundament≈Ø)\n",
    "4. **Odstranƒõn√≠ NaN** hodnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad25175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definice features a targets\n",
    "\n",
    "# OHLCV + technick√© indik√°tory (features)\n",
    "FEATURE_COLS = [\n",
    "    'open', 'high', 'low', 'close', 'volume',\n",
    "    'returns', 'volatility_12m', 'rsi_14',\n",
    "    'macd', 'macd_signal', 'macd_hist',\n",
    "    'sma_3', 'sma_6', 'sma_12',\n",
    "    'ema_3', 'ema_6', 'ema_12',\n",
    "    'volume_change', 'price_momentum'\n",
    "]\n",
    "\n",
    "# Fundament√°ln√≠ metriky (targets)\n",
    "TARGET_COLS = [\n",
    "    'PE', 'PB', 'PS', 'EV_EBITDA',\n",
    "    'ROE', 'ROA', 'Profit_Margin', 'Operating_Margin', 'Gross_Margin',\n",
    "    'Debt_to_Equity', 'Current_Ratio', 'Quick_Ratio',\n",
    "    'Revenue_Growth_YoY', 'Earnings_Growth_YoY'\n",
    "]\n",
    "\n",
    "print(f\"üìä Features: {len(FEATURE_COLS)}\")\n",
    "for f in FEATURE_COLS:\n",
    "    print(f\"   ‚Ä¢ {f}\")\n",
    "\n",
    "print(f\"\\nüéØ Targets: {len(TARGET_COLS)}\")\n",
    "for t in TARGET_COLS:\n",
    "    print(f\"   ‚Ä¢ {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(ohlcv: pd.DataFrame, fundamentals: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    P≈ôiprav√≠ tr√©novac√≠ data spojen√≠m OHLCV s fundamenty.\n",
    "    \n",
    "    Strategie:\n",
    "    1. Pro ka≈æd√Ω ticker p≈ôid√°me fundamenty k nejnovƒõj≈°√≠m OHLCV dat≈Øm\n",
    "    2. Pou≈æ√≠v√°me forward-fill pro roz≈°√≠≈ôen√≠ datasetu\n",
    "    \"\"\"\n",
    "    merged_data = []\n",
    "    \n",
    "    for ticker in ohlcv['ticker'].unique():\n",
    "        # OHLCV pro tento ticker\n",
    "        ticker_ohlcv = ohlcv[ohlcv['ticker'] == ticker].copy()\n",
    "        ticker_ohlcv = ticker_ohlcv.sort_values('date')\n",
    "        \n",
    "        # Fundamenty pro tento ticker\n",
    "        ticker_fund = fundamentals[fundamentals['ticker'] == ticker]\n",
    "        \n",
    "        if ticker_fund.empty:\n",
    "            continue\n",
    "        \n",
    "        # P≈ôid√°me fundamenty ke v≈°em OHLCV z√°znam≈Øm (forward fill simulace)\n",
    "        for col in TARGET_COLS:\n",
    "            if col in ticker_fund.columns:\n",
    "                ticker_ohlcv[col] = ticker_fund[col].values[0]\n",
    "            else:\n",
    "                ticker_ohlcv[col] = np.nan\n",
    "        \n",
    "        merged_data.append(ticker_ohlcv)\n",
    "    \n",
    "    result = pd.concat(merged_data, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "# P≈ô√≠prava dat\n",
    "print(\"üîÑ P≈ô√≠prava tr√©novac√≠ch dat...\")\n",
    "training_df = prepare_training_data(ohlcv_df, fundamentals_df)\n",
    "\n",
    "print(f\"\\n‚úì Merged dataset: {len(training_df):,} z√°znam≈Ø\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d262944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odstranƒõn√≠ ≈ô√°dk≈Ø s NaN v features nebo targets\n",
    "print(\"üßπ ƒåi≈°tƒõn√≠ dat...\")\n",
    "\n",
    "# P≈ôed ƒçi≈°tƒõn√≠m\n",
    "print(f\"   P≈ôed ƒçi≈°tƒõn√≠m: {len(training_df):,} z√°znam≈Ø\")\n",
    "\n",
    "# Kontrola dostupn√Ωch sloupc≈Ø\n",
    "available_features = [f for f in FEATURE_COLS if f in training_df.columns]\n",
    "available_targets = [t for t in TARGET_COLS if t in training_df.columns]\n",
    "\n",
    "print(f\"   Dostupn√© features: {len(available_features)}/{len(FEATURE_COLS)}\")\n",
    "print(f\"   Dostupn√© targets: {len(available_targets)}/{len(TARGET_COLS)}\")\n",
    "\n",
    "# Odstranƒõn√≠ NaN\n",
    "all_cols = available_features + available_targets\n",
    "clean_df = training_df.dropna(subset=all_cols)\n",
    "\n",
    "print(f\"   Po ƒçi≈°tƒõn√≠: {len(clean_df):,} z√°znam≈Ø\")\n",
    "print(f\"   Odstranƒõno: {len(training_df) - len(clean_df):,} z√°znam≈Ø\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a722d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ô√≠prava X (features) a y (targets)\n",
    "X = clean_df[available_features].values\n",
    "y = clean_df[available_targets].values\n",
    "\n",
    "print(f\"\\nüìä Fin√°ln√≠ dataset:\")\n",
    "print(f\"   X shape: {X.shape} (samples √ó features)\")\n",
    "print(f\"   y shape: {y.shape} (samples √ó targets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9cb66",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train/Test Split\n",
    "\n",
    "### 5.1 Chronologick√Ω Split\n",
    "\n",
    "Pro finanƒçn√≠ data **NIKDY** nepou≈æ√≠v√°me n√°hodn√Ω split (data leakage).\n",
    "\n",
    "Pou≈æ√≠v√°me **chronologick√Ω split**:\n",
    "- **Training**: 2015-2023 (80%)\n",
    "- **Test**: 2024-2025 (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f72976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronologick√Ω split\n",
    "# Proto≈æe m√°me forward-filled data, pou≈æijeme jednoduch√Ω split podle indexu\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"üìä Train/Test Split:\")\n",
    "print(f\"   Training: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizace features (pro konzistenci, i kdy≈æ RF ji nepot≈ôebuje)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Features standardizov√°ny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c772c",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Tr√©nov√°n√≠ Random Forest Modelu\n",
    "\n",
    "### 6.1 Hyperparametry\n",
    "\n",
    "| Parametr | Hodnota | Vysvƒõtlen√≠ |\n",
    "|----------|---------|------------|\n",
    "| `n_estimators` | 200 | Poƒçet strom≈Ø - v√≠ce = stabilnƒõj≈°√≠ |\n",
    "| `max_depth` | 15 | Hloubka stromu - prevence overfittingu |\n",
    "| `min_samples_split` | 5 | Min. samples pro split |\n",
    "| `min_samples_leaf` | 2 | Min. samples v listu |\n",
    "| `n_jobs` | -1 | Paralelizace na v≈°ech CPU |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurace modelu\n",
    "RF_PARAMS = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 15,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"üå≤ Random Forest Konfigurace:\")\n",
    "for param, value in RF_PARAMS.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Tr√©nov√°n√≠ modelu\n",
    "print(\"üöÄ Tr√©nov√°n√≠ Multi-Output Random Forest...\")\n",
    "print(f\"   Targets: {len(available_targets)}\")\n",
    "print(f\"   Training samples: {len(X_train):,}\")\n",
    "print()\n",
    "\n",
    "# Vytvo≈ôen√≠ a tr√©nov√°n√≠ modelu\n",
    "base_rf = RandomForestRegressor(**RF_PARAMS)\n",
    "model = MultiOutputRegressor(base_rf)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Model natr√©nov√°n!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eec693",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Evaluace Modelu\n",
    "\n",
    "### 7.1 Metriky\n",
    "\n",
    "Pro ka≈ædou fundament√°ln√≠ metriku poƒç√≠t√°me:\n",
    "\n",
    "| Metrika | Formule | Interpretace |\n",
    "|---------|---------|-------------|\n",
    "| **MAE** | $\\frac{1}{n}\\sum|y_i - \\hat{y}_i|$ | Pr≈Ømƒõrn√° absolutn√≠ chyba |\n",
    "| **RMSE** | $\\sqrt{\\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2}$ | Penalizuje velk√© chyby |\n",
    "| **R¬≤** | $1 - \\frac{SS_{res}}{SS_{tot}}$ | Vysvƒõtlen√° variance (0-1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predikce na test setu\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"‚úì Predikce dokonƒçeny: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6927d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluace pro ka≈æd√Ω target\n",
    "results = []\n",
    "\n",
    "print(\"üìä EVALUACE MODELU\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Target':<25} {'MAE':>10} {'RMSE':>10} {'R¬≤':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, target in enumerate(available_targets):\n",
    "    y_true_i = y_test[:, i]\n",
    "    y_pred_i = y_pred[:, i]\n",
    "    \n",
    "    mae = mean_absolute_error(y_true_i, y_pred_i)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_i, y_pred_i))\n",
    "    r2 = r2_score(y_true_i, y_pred_i)\n",
    "    \n",
    "    results.append({\n",
    "        'Target': target,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })\n",
    "    \n",
    "    # Barevn√© oznaƒçen√≠ R¬≤\n",
    "    r2_color = 'üü¢' if r2 > 0.5 else 'üü°' if r2 > 0.2 else 'üî¥'\n",
    "    print(f\"{target:<25} {mae:>10.3f} {rmse:>10.3f} {r2:>9.3f} {r2_color}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Pr≈Ømƒõrn√© metriky\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"{'PR≈ÆMƒöR':<25} {results_df['MAE'].mean():>10.3f} {results_df['RMSE'].mean():>10.3f} {results_df['R2'].mean():>9.3f}\")\n",
    "\n",
    "print(\"\\nüü¢ R¬≤ > 0.5: Dobr√° predikce\")\n",
    "print(\"üü° R¬≤ 0.2-0.5: St≈ôedn√≠ predikce\")\n",
    "print(\"üî¥ R¬≤ < 0.2: Slab√° predikce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace v√Ωsledk≈Ø\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. R¬≤ pro ka≈æd√Ω target\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['green' if r > 0.5 else 'orange' if r > 0.2 else 'red' \n",
    "          for r in results_df['R2']]\n",
    "bars = ax1.barh(results_df['Target'], results_df['R2'], color=colors)\n",
    "ax1.axvline(0.5, color='green', linestyle='--', alpha=0.5, label='Dobr√° (0.5)')\n",
    "ax1.axvline(0.2, color='orange', linestyle='--', alpha=0.5, label='St≈ôedn√≠ (0.2)')\n",
    "ax1.set_xlabel('R¬≤ Score')\n",
    "ax1.set_title('R¬≤ Score pro Ka≈ædou Fundament√°ln√≠ Metriku', fontweight='bold')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_xlim(-0.1, 1.0)\n",
    "\n",
    "# 2. MAE vs RMSE\n",
    "ax2 = axes[0, 1]\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "ax2.bar(x - width/2, results_df['MAE'], width, label='MAE', color='steelblue')\n",
    "ax2.bar(x + width/2, results_df['RMSE'], width, label='RMSE', color='coral')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(results_df['Target'], rotation=45, ha='right')\n",
    "ax2.set_ylabel('Chyba')\n",
    "ax2.set_title('MAE vs RMSE', fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Scatter plot: Actual vs Predicted (pro nejlep≈°√≠ target)\n",
    "best_idx = results_df['R2'].idxmax()\n",
    "best_target = results_df.loc[best_idx, 'Target']\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(y_test[:, best_idx], y_pred[:, best_idx], alpha=0.5, s=20)\n",
    "ax3.plot([y_test[:, best_idx].min(), y_test[:, best_idx].max()],\n",
    "         [y_test[:, best_idx].min(), y_test[:, best_idx].max()],\n",
    "         'r--', linewidth=2, label='Ide√°ln√≠')\n",
    "ax3.set_xlabel('Skuteƒçn√° hodnota')\n",
    "ax3.set_ylabel('Predikovan√° hodnota')\n",
    "ax3.set_title(f'Actual vs Predicted: {best_target} (R¬≤={results_df.loc[best_idx, \"R2\"]:.3f})', fontweight='bold')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Distribuce R¬≤\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(results_df['R2'], bins=10, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax4.axvline(results_df['R2'].mean(), color='red', linestyle='--', \n",
    "            label=f'Pr≈Ømƒõr: {results_df[\"R2\"].mean():.3f}')\n",
    "ax4.set_xlabel('R¬≤ Score')\n",
    "ax4.set_ylabel('Poƒçet target≈Ø')\n",
    "ax4.set_title('Distribuce R¬≤ Score', fontweight='bold')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{DATA_PATH}/fundamental_predictor_evaluation.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüíæ Graf ulo≈æen: {DATA_PATH}/fundamental_predictor_evaluation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139240d",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Feature Importance\n",
    "\n",
    "Kter√© OHLCV features jsou nejd≈Øle≈æitƒõj≈°√≠ pro predikci fundament≈Ø?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfa132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregovan√° feature importance p≈ôes v≈°echny targets\n",
    "importances = []\n",
    "\n",
    "for estimator in model.estimators_:\n",
    "    importances.append(estimator.feature_importances_)\n",
    "\n",
    "# Pr≈Ømƒõr p≈ôes v≈°echny targets\n",
    "avg_importance = np.mean(importances, axis=0)\n",
    "\n",
    "# DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Importance': avg_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"üìä FEATURE IMPORTANCE (pr≈Ømƒõr p≈ôes v≈°echny targets)\")\n",
    "print(\"=\"*50)\n",
    "for _, row in importance_df.iterrows():\n",
    "    bar = '‚ñà' * int(row['Importance'] * 50)\n",
    "    print(f\"{row['Feature']:<20} {row['Importance']:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(importance_df)))\n",
    "bars = ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Feature Importance pro Predikci Fundament≈Ø', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Anotace\n",
    "for bar, val in zip(bars, importance_df['Importance']):\n",
    "    ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{DATA_PATH}/feature_importance.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüíæ Graf ulo≈æen: {DATA_PATH}/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3752d",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Ulo≈æen√≠ Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c78f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulo≈æen√≠ modelu a scaleru\n",
    "model_path = f\"{MODEL_PATH}/fundamental_predictor.pkl\"\n",
    "scaler_path = f\"{MODEL_PATH}/feature_scaler.pkl\"\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(f\"üíæ Model ulo≈æen: {model_path}\")\n",
    "print(f\"üíæ Scaler ulo≈æen: {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulo≈æen√≠ metadat modelu\n",
    "metadata = {\n",
    "    'features': available_features,\n",
    "    'targets': available_targets,\n",
    "    'rf_params': RF_PARAMS,\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'avg_r2': results_df['R2'].mean(),\n",
    "    'avg_mae': results_df['MAE'].mean(),\n",
    "    'created': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Ulo≈æen√≠ jako JSON\n",
    "import json\n",
    "metadata_path = f\"{MODEL_PATH}/fundamental_predictor_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Metadata ulo≈æena: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59577262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulo≈æen√≠ v√Ωsledk≈Ø evaluace\n",
    "results_path = f\"{DATA_PATH}/fundamental_predictor_results.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"üíæ V√Ωsledky ulo≈æeny: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf4bf3",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Shrnut√≠ a Dal≈°√≠ Kroky\n",
    "\n",
    "### ‚úÖ Dokonƒçeno:\n",
    "\n",
    "| √ökol | Status |\n",
    "|------|--------|\n",
    "| P≈ô√≠prava tr√©novac√≠ch dat | ‚úÖ |\n",
    "| Tr√©nov√°n√≠ Multi-Output RF | ‚úÖ |\n",
    "| Evaluace (MAE, RMSE, R¬≤) | ‚úÖ |\n",
    "| Feature Importance anal√Ωza | ‚úÖ |\n",
    "| Ulo≈æen√≠ modelu | ‚úÖ |\n",
    "\n",
    "### üìÅ Vytvo≈ôen√© soubory:\n",
    "\n",
    "| Soubor | Popis |\n",
    "|--------|-------|\n",
    "| `models/fundamental_predictor.pkl` | Natr√©novan√Ω RF model |\n",
    "| `models/feature_scaler.pkl` | StandardScaler pro features |\n",
    "| `models/fundamental_predictor_metadata.json` | Metadata modelu |\n",
    "| `data/fundamental_predictor_results.csv` | Evaluaƒçn√≠ metriky |\n",
    "\n",
    "### ‚û°Ô∏è Dal≈°√≠ notebook:\n",
    "\n",
    "**Notebook 03: Doplnƒõn√≠ Historick√Ωch Dat**\n",
    "- Pou≈æit√≠ natr√©novan√©ho modelu pro imputaci 2015-2024\n",
    "- Validace predikovan√Ωch hodnot\n",
    "- Vytvo≈ôen√≠ kompletn√≠ho 10-let√©ho datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f367428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin√°ln√≠ shrnut√≠\n",
    "print(\"=\"*70)\n",
    "print(\"üìä NOTEBOOK 02 - SHRNUT√ç\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüå≤ Model: Multi-Output Random Forest\")\n",
    "print(f\"   ‚Ä¢ Stromy: {RF_PARAMS['n_estimators']}\")\n",
    "print(f\"   ‚Ä¢ Hloubka: {RF_PARAMS['max_depth']}\")\n",
    "\n",
    "print(f\"\\nüìä V√Ωsledky:\")\n",
    "print(f\"   ‚Ä¢ Pr≈Ømƒõrn√© R¬≤: {results_df['R2'].mean():.3f}\")\n",
    "print(f\"   ‚Ä¢ Pr≈Ømƒõrn√© MAE: {results_df['MAE'].mean():.3f}\")\n",
    "print(f\"   ‚Ä¢ Nejlep≈°√≠ target: {best_target} (R¬≤={results_df.loc[best_idx, 'R2']:.3f})\")\n",
    "\n",
    "print(f\"\\nüîù Top 3 nejd≈Øle≈æitƒõj≈°√≠ features:\")\n",
    "for i, (_, row) in enumerate(importance_df.head(3).iterrows()):\n",
    "    print(f\"   {i+1}. {row['Feature']}: {row['Importance']:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Model p≈ôipraven pro Notebook 03!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

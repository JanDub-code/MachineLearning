{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249b09b8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Teoretick√Ω √övod\n",
    "\n",
    "### 1.1 Probl√©m Ne√∫plnosti Dat\n",
    "\n",
    "**Situace:**\n",
    "- OHLCV data: 10 let (2015-2025) ‚úÖ\n",
    "- Fundament√°ln√≠ data: pouze ~1.5 roku (2024-2025) ‚ö†Ô∏è\n",
    "\n",
    "**≈òe≈°en√≠:** Pou≈æ√≠t natr√©novan√Ω RF model pro **zpƒõtnou imputaci** fundament≈Ø.\n",
    "\n",
    "### 1.2 Validita P≈ô√≠stupu\n",
    "\n",
    "Proƒç je tento p≈ô√≠stup validn√≠?\n",
    "\n",
    "| Argument | Vysvƒõtlen√≠ |\n",
    "|----------|------------|\n",
    "| **Korelace OHLCV-Fundamenty** | Cenov√© vzory reflektuj√≠ fundament√°ln√≠ hodnotu |\n",
    "| **Konzistence v ƒçase** | Fundamenty se mƒõn√≠ pomalu (ƒçtvrtletnƒõ) |\n",
    "| **Cross-validation** | Model testov√°n na out-of-sample datech |\n",
    "\n",
    "### 1.3 Omezen√≠\n",
    "\n",
    "‚ö†Ô∏è **D≈Øle≈æit√©:**\n",
    "- Predikovan√© hodnoty jsou **aproximace**, ne p≈ôesn√° ƒç√≠sla\n",
    "- Vhodn√© pro **trendovou anal√Ωzu**, ne pro p≈ôesn√© valuace\n",
    "- Extr√©mn√≠ ud√°losti (COVID, finanƒçn√≠ krize) mohou b√Ωt ≈°patnƒõ zachyceny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa242f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Setup Prost≈ôed√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace (pro Colab)\n",
    "!pip install pandas numpy scikit-learn joblib matplotlib seaborn tqdm -q\n",
    "\n",
    "print(\"‚úì Knihovny nainstalov√°ny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a79a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import knihoven\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Knihovny naƒçteny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ôipojen√≠ Google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DRIVE_PATH = '/content/drive/MyDrive/MachineLearning'\n",
    "    RUNNING_ON_COLAB = True\n",
    "    print(f\"‚úì Google Drive p≈ôipojen: {DRIVE_PATH}\")\n",
    "except:\n",
    "    DRIVE_PATH = '.'\n",
    "    RUNNING_ON_COLAB = False\n",
    "    print(\"‚ÑπÔ∏è Lok√°ln√≠ prost≈ôed√≠\")\n",
    "\n",
    "# Cesty\n",
    "DATA_PATH = f\"{DRIVE_PATH}/data\"\n",
    "MODEL_PATH = f\"{DRIVE_PATH}/models\"\n",
    "COMPLETE_PATH = f\"{DATA_PATH}/complete\"\n",
    "os.makedirs(COMPLETE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9294a",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Naƒçten√≠ Dat a Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ natr√©novan√©ho modelu\n",
    "model_path = f\"{MODEL_PATH}/fundamental_predictor.pkl\"\n",
    "scaler_path = f\"{MODEL_PATH}/feature_scaler.pkl\"\n",
    "metadata_path = f\"{MODEL_PATH}/fundamental_predictor_metadata.json\"\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "FEATURE_COLS = metadata['features']\n",
    "TARGET_COLS = metadata['targets']\n",
    "\n",
    "print(f\"‚úì Model naƒçten\")\n",
    "print(f\"   Features: {len(FEATURE_COLS)}\")\n",
    "print(f\"   Targets: {len(TARGET_COLS)}\")\n",
    "print(f\"   Pr≈Ømƒõrn√© R¬≤: {metadata['avg_r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a217c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ OHLCV dat\n",
    "ohlcv_path = f\"{DATA_PATH}/ohlcv/all_sectors_ohlcv_10y.csv\"\n",
    "ohlcv_df = pd.read_csv(ohlcv_path, parse_dates=['date'])\n",
    "\n",
    "print(f\"\\nüìà OHLCV Data:\")\n",
    "print(f\"   Z√°znam≈Ø: {len(ohlcv_df):,}\")\n",
    "print(f\"   Ticker≈Ø: {ohlcv_df['ticker'].nunique()}\")\n",
    "print(f\"   Obdob√≠: {ohlcv_df['date'].min().strftime('%Y-%m')} ‚Üí {ohlcv_df['date'].max().strftime('%Y-%m')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ re√°ln√Ωch fundament≈Ø\n",
    "fund_path = f\"{DATA_PATH}/fundamentals/all_sectors_fundamentals.csv\"\n",
    "real_fundamentals = pd.read_csv(fund_path, parse_dates=['date'])\n",
    "\n",
    "print(f\"\\nüìä Re√°ln√© Fundamenty:\")\n",
    "print(f\"   Z√°znam≈Ø: {len(real_fundamentals)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163aff4",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Imputace Historick√Ωch Fundament≈Ø\n",
    "\n",
    "### 4.1 Strategie\n",
    "\n",
    "Pro ka≈æd√Ω mƒõs√≠c v obdob√≠ 2015-2024:\n",
    "1. Extrahuj OHLCV features\n",
    "2. Standardizuj features\n",
    "3. Predikuj 14 fundament√°ln√≠ch metrik\n",
    "4. P≈ôidej k datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_fundamentals(ohlcv: pd.DataFrame, model, scaler, \n",
    "                        feature_cols: list, target_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Imputuje fundament√°ln√≠ metriky pomoc√≠ natr√©novan√©ho RF modelu.\n",
    "    \n",
    "    Args:\n",
    "        ohlcv: DataFrame s OHLCV daty a technick√Ωmi indik√°tory\n",
    "        model: Natr√©novan√Ω Multi-Output RF model\n",
    "        scaler: StandardScaler pro features\n",
    "        feature_cols: Seznam feature sloupc≈Ø\n",
    "        target_cols: Seznam target sloupc≈Ø\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame s imputovan√Ωmi fundamenty\n",
    "    \"\"\"\n",
    "    result = ohlcv.copy()\n",
    "    \n",
    "    # Kontrola dostupn√Ωch features\n",
    "    available_features = [f for f in feature_cols if f in result.columns]\n",
    "    \n",
    "    if len(available_features) < len(feature_cols):\n",
    "        missing = set(feature_cols) - set(available_features)\n",
    "        print(f\"‚ö†Ô∏è Chybƒõj√≠c√≠ features: {missing}\")\n",
    "        return result\n",
    "    \n",
    "    # Odstranƒõn√≠ ≈ô√°dk≈Ø s NaN ve features\n",
    "    valid_mask = result[available_features].notna().all(axis=1)\n",
    "    valid_data = result[valid_mask].copy()\n",
    "    \n",
    "    print(f\"üìä Imputace pro {len(valid_data):,} z√°znam≈Ø...\")\n",
    "    \n",
    "    if len(valid_data) == 0:\n",
    "        print(\"‚ö†Ô∏è ≈Ω√°dn√° validn√≠ data pro imputaci\")\n",
    "        return result\n",
    "    \n",
    "    # Extrakce features\n",
    "    X = valid_data[available_features].values\n",
    "    \n",
    "    # Standardizace\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Predikce\n",
    "    predictions = model.predict(X_scaled)\n",
    "    \n",
    "    # P≈ôid√°n√≠ predikc√≠ do DataFrame\n",
    "    for i, col in enumerate(target_cols):\n",
    "        result.loc[valid_mask, col] = predictions[:, i]\n",
    "    \n",
    "    print(f\"‚úì Imputov√°no {len(target_cols)} metrik\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Imputace\n",
    "print(\"üîÑ Imputace historick√Ωch fundament≈Ø...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "imputed_df = impute_fundamentals(\n",
    "    ohlcv_df, \n",
    "    model, \n",
    "    scaler, \n",
    "    FEATURE_COLS, \n",
    "    TARGET_COLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee443c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrola imputovan√Ωch hodnot\n",
    "print(\"\\nüìä STATISTIKY IMPUTOVAN√ùCH HODNOT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in TARGET_COLS:\n",
    "    if col in imputed_df.columns:\n",
    "        values = imputed_df[col].dropna()\n",
    "        print(f\"{col:<25} min={values.min():>10.2f}  max={values.max():>10.2f}  mean={values.mean():>10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d652b9",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Validace Predikc√≠\n",
    "\n",
    "### 5.1 Sanity Checks\n",
    "\n",
    "Kontrolujeme, ≈æe predikovan√© hodnoty jsou v rozumn√Ωch rozmez√≠ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_predictions(df: pd.DataFrame, target_cols: list) -> dict:\n",
    "    \"\"\"\n",
    "    Validuje predikovan√© hodnoty pomoc√≠ sanity checks.\n",
    "    \n",
    "    Kontroly:\n",
    "    - P/E by mƒõlo b√Ωt 0-100 (vƒõt≈°ina)\n",
    "    - ROE/ROA by mƒõlo b√Ωt -1 a≈æ 1\n",
    "    - Debt/Equity by mƒõlo b√Ωt >= 0\n",
    "    \"\"\"\n",
    "    validation = {}\n",
    "    \n",
    "    # Definice oƒçek√°van√Ωch rozmez√≠\n",
    "    expected_ranges = {\n",
    "        'PE': (0, 200),\n",
    "        'PB': (0, 50),\n",
    "        'PS': (0, 100),\n",
    "        'EV_EBITDA': (-10, 100),\n",
    "        'ROE': (-2, 2),\n",
    "        'ROA': (-1, 1),\n",
    "        'Profit_Margin': (-1, 1),\n",
    "        'Operating_Margin': (-1, 1),\n",
    "        'Gross_Margin': (-1, 1),\n",
    "        'Debt_to_Equity': (0, 1000),\n",
    "        'Current_Ratio': (0, 20),\n",
    "        'Quick_Ratio': (0, 20),\n",
    "        'Revenue_Growth_YoY': (-1, 5),\n",
    "        'Earnings_Growth_YoY': (-5, 10)\n",
    "    }\n",
    "    \n",
    "    print(\"üìä VALIDACE PREDIKC√ç\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Metrika':<25} {'V rozmez√≠':>12} {'Pod':>10} {'Nad':>10} {'Status':>10}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for col in target_cols:\n",
    "        if col not in df.columns or col not in expected_ranges:\n",
    "            continue\n",
    "            \n",
    "        values = df[col].dropna()\n",
    "        if len(values) == 0:\n",
    "            continue\n",
    "            \n",
    "        min_val, max_val = expected_ranges[col]\n",
    "        \n",
    "        in_range = ((values >= min_val) & (values <= max_val)).sum()\n",
    "        below = (values < min_val).sum()\n",
    "        above = (values > max_val).sum()\n",
    "        \n",
    "        in_range_pct = in_range / len(values) * 100\n",
    "        \n",
    "        status = '‚úÖ' if in_range_pct > 90 else '‚ö†Ô∏è' if in_range_pct > 70 else '‚ùå'\n",
    "        \n",
    "        validation[col] = {\n",
    "            'in_range_pct': in_range_pct,\n",
    "            'below': below,\n",
    "            'above': above,\n",
    "            'status': status\n",
    "        }\n",
    "        \n",
    "        print(f\"{col:<25} {in_range_pct:>11.1f}% {below:>10} {above:>10} {status:>10}\")\n",
    "    \n",
    "    return validation\n",
    "\n",
    "# Validace\n",
    "validation_results = validate_predictions(imputed_df, TARGET_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clipping extr√©mn√≠ch hodnot\n",
    "def clip_extreme_values(df: pd.DataFrame, target_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    O≈ô√≠zne extr√©mn√≠ hodnoty na rozumn√© rozmez√≠.\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    clip_ranges = {\n",
    "        'PE': (0, 200),\n",
    "        'PB': (0, 50),\n",
    "        'PS': (0, 100),\n",
    "        'EV_EBITDA': (-10, 100),\n",
    "        'ROE': (-2, 2),\n",
    "        'ROA': (-1, 1),\n",
    "        'Profit_Margin': (-1, 1),\n",
    "        'Operating_Margin': (-1, 1),\n",
    "        'Gross_Margin': (0, 1),\n",
    "        'Debt_to_Equity': (0, 500),\n",
    "        'Current_Ratio': (0, 10),\n",
    "        'Quick_Ratio': (0, 10),\n",
    "        'Revenue_Growth_YoY': (-1, 3),\n",
    "        'Earnings_Growth_YoY': (-3, 5)\n",
    "    }\n",
    "    \n",
    "    for col in target_cols:\n",
    "        if col in result.columns and col in clip_ranges:\n",
    "            min_val, max_val = clip_ranges[col]\n",
    "            before = result[col].isna().sum()\n",
    "            result[col] = result[col].clip(min_val, max_val)\n",
    "            \n",
    "    print(\"‚úì Extr√©mn√≠ hodnoty o≈ô√≠znuty\")\n",
    "    return result\n",
    "\n",
    "# Clipping\n",
    "imputed_df = clip_extreme_values(imputed_df, TARGET_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dc6e0",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Merge s Re√°ln√Ωmi Daty\n",
    "\n",
    "Pro obdob√≠ 2024-2025 pou≈æ√≠v√°me **re√°ln√° data** m√≠sto predikc√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_real_data(imputed: pd.DataFrame, real: pd.DataFrame, \n",
    "                         target_cols: list, cutoff_date: str = '2024-01-01') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Nahrad√≠ imputovan√© hodnoty re√°ln√Ωmi daty pro obdob√≠ po cutoff_date.\n",
    "    \n",
    "    Args:\n",
    "        imputed: DataFrame s imputovan√Ωmi hodnotami\n",
    "        real: DataFrame s re√°ln√Ωmi fundamenty\n",
    "        target_cols: Seznam target sloupc≈Ø\n",
    "        cutoff_date: Datum od kter√©ho pou≈æ√≠t re√°ln√° data\n",
    "    \n",
    "    Returns:\n",
    "        Merged DataFrame\n",
    "    \"\"\"\n",
    "    result = imputed.copy()\n",
    "    cutoff = pd.to_datetime(cutoff_date)\n",
    "    \n",
    "    # Pro ka≈æd√Ω ticker nahrad√≠me imputovan√© hodnoty re√°ln√Ωmi\n",
    "    replaced_count = 0\n",
    "    \n",
    "    for ticker in real['ticker'].unique():\n",
    "        ticker_real = real[real['ticker'] == ticker]\n",
    "        \n",
    "        if ticker_real.empty:\n",
    "            continue\n",
    "        \n",
    "        # Najdi z√°znamy po cutoff date\n",
    "        mask = (result['ticker'] == ticker) & (result['date'] >= cutoff)\n",
    "        \n",
    "        # Nahraƒè imputovan√© hodnoty re√°ln√Ωmi\n",
    "        for col in target_cols:\n",
    "            if col in ticker_real.columns and col in result.columns:\n",
    "                real_value = ticker_real[col].values[0]\n",
    "                if pd.notna(real_value):\n",
    "                    result.loc[mask, col] = real_value\n",
    "                    replaced_count += mask.sum()\n",
    "    \n",
    "    print(f\"‚úì Nahrazeno {replaced_count:,} imputovan√Ωch hodnot re√°ln√Ωmi daty\")\n",
    "    return result\n",
    "\n",
    "# Merge\n",
    "print(\"\\nüîÑ Merge s re√°ln√Ωmi daty...\")\n",
    "complete_df = merge_with_real_data(imputed_df, real_fundamentals, TARGET_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc532adf",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Finalizace Datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee405ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ôid√°n√≠ p≈ô√≠znaku zdroje dat\n",
    "cutoff = pd.to_datetime('2024-01-01')\n",
    "complete_df['data_source'] = np.where(\n",
    "    complete_df['date'] >= cutoff, \n",
    "    'real', \n",
    "    'imputed'\n",
    ")\n",
    "\n",
    "# Statistiky\n",
    "source_counts = complete_df['data_source'].value_counts()\n",
    "print(f\"\\nüìä Zdroj dat:\")\n",
    "print(f\"   Imputovan√©: {source_counts.get('imputed', 0):,}\")\n",
    "print(f\"   Re√°ln√©: {source_counts.get('real', 0):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulo≈æen√≠ kompletn√≠ho datasetu\n",
    "complete_path = f\"{COMPLETE_PATH}/all_sectors_complete_10y.csv\"\n",
    "complete_df.to_csv(complete_path, index=False)\n",
    "\n",
    "print(f\"üíæ Kompletn√≠ dataset ulo≈æen: {complete_path}\")\n",
    "print(f\"   Z√°znam≈Ø: {len(complete_df):,}\")\n",
    "print(f\"   Sloupc≈Ø: {len(complete_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05db400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulo≈æen√≠ po sektorech\n",
    "for sector in complete_df['sector'].unique():\n",
    "    sector_df = complete_df[complete_df['sector'] == sector]\n",
    "    sector_path = f\"{COMPLETE_PATH}/{sector}_complete_10y.csv\"\n",
    "    sector_df.to_csv(sector_path, index=False)\n",
    "    print(f\"üíæ {sector}: {len(sector_df):,} z√°znam≈Ø ‚Üí {sector_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3cf1e",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Vizualizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566aee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace imputovan√Ωch vs re√°ln√Ωch dat\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. P/E v ƒçase pro jeden ticker\n",
    "ax1 = axes[0, 0]\n",
    "sample_ticker = complete_df['ticker'].unique()[0]\n",
    "sample_data = complete_df[complete_df['ticker'] == sample_ticker].sort_values('date')\n",
    "\n",
    "imputed_mask = sample_data['data_source'] == 'imputed'\n",
    "real_mask = sample_data['data_source'] == 'real'\n",
    "\n",
    "ax1.plot(sample_data[imputed_mask]['date'], sample_data[imputed_mask]['PE'], \n",
    "         'b-', label='Imputovan√©', alpha=0.7)\n",
    "ax1.plot(sample_data[real_mask]['date'], sample_data[real_mask]['PE'], \n",
    "         'r-', label='Re√°ln√©', linewidth=2)\n",
    "ax1.axvline(pd.to_datetime('2024-01-01'), color='green', linestyle='--', \n",
    "            label='Cutoff (2024)')\n",
    "ax1.set_title(f'P/E Ratio v ƒåase: {sample_ticker}', fontweight='bold')\n",
    "ax1.set_xlabel('Datum')\n",
    "ax1.set_ylabel('P/E')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribuce imputovan√Ωch vs re√°ln√Ωch\n",
    "ax2 = axes[0, 1]\n",
    "imputed_pe = complete_df[complete_df['data_source'] == 'imputed']['PE'].dropna()\n",
    "real_pe = complete_df[complete_df['data_source'] == 'real']['PE'].dropna()\n",
    "\n",
    "ax2.hist(imputed_pe, bins=30, alpha=0.5, label='Imputovan√©', color='blue', density=True)\n",
    "ax2.hist(real_pe, bins=30, alpha=0.5, label='Re√°ln√©', color='red', density=True)\n",
    "ax2.set_title('Distribuce P/E: Imputovan√© vs Re√°ln√©', fontweight='bold')\n",
    "ax2.set_xlabel('P/E Ratio')\n",
    "ax2.set_ylabel('Hustota')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Poƒçet z√°znam≈Ø v ƒçase\n",
    "ax3 = axes[1, 0]\n",
    "monthly_counts = complete_df.groupby([complete_df['date'].dt.to_period('Y'), 'data_source']).size().unstack(fill_value=0)\n",
    "monthly_counts.plot(kind='bar', stacked=True, ax=ax3, color=['blue', 'red'])\n",
    "ax3.set_title('Poƒçet Z√°znam≈Ø po Letech', fontweight='bold')\n",
    "ax3.set_xlabel('Rok')\n",
    "ax3.set_ylabel('Poƒçet z√°znam≈Ø')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.legend(['Imputovan√©', 'Re√°ln√©'])\n",
    "\n",
    "# 4. Korelace fundament≈Ø\n",
    "ax4 = axes[1, 1]\n",
    "fund_cols = ['PE', 'PB', 'ROE', 'ROA', 'Debt_to_Equity']\n",
    "available_fund = [c for c in fund_cols if c in complete_df.columns]\n",
    "corr = complete_df[available_fund].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='RdYlGn', center=0, ax=ax4, fmt='.2f')\n",
    "ax4.set_title('Korelace Fundament√°ln√≠ch Metrik', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{DATA_PATH}/data_completion_overview.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüíæ Graf ulo≈æen: {DATA_PATH}/data_completion_overview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54063549",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Shrnut√≠\n",
    "\n",
    "### ‚úÖ Dokonƒçeno:\n",
    "\n",
    "| √ökol | Status |\n",
    "|------|--------|\n",
    "| Naƒçten√≠ modelu z Notebooku 02 | ‚úÖ |\n",
    "| Imputace 2015-2024 | ‚úÖ |\n",
    "| Validace predikc√≠ | ‚úÖ |\n",
    "| Merge s re√°ln√Ωmi daty | ‚úÖ |\n",
    "| Ulo≈æen√≠ kompletn√≠ho datasetu | ‚úÖ |\n",
    "\n",
    "### üìÅ Vytvo≈ôen√© soubory:\n",
    "\n",
    "| Soubor | Popis |\n",
    "|--------|-------|\n",
    "| `data/complete/all_sectors_complete_10y.csv` | Kompletn√≠ 10-let√Ω dataset |\n",
    "| `data/complete/{Sector}_complete_10y.csv` | Sektorov√© datasety |\n",
    "\n",
    "### ‚û°Ô∏è Dal≈°√≠ notebook:\n",
    "\n",
    "**Notebook 04: Tr√©nov√°n√≠ Price Classifier**\n",
    "- Tern√°rn√≠ klasifikace: DOWN / HOLD / UP\n",
    "- Random Forest Classifier\n",
    "- Confusion Matrix, Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin√°ln√≠ shrnut√≠\n",
    "print(\"=\"*70)\n",
    "print(\"üìä NOTEBOOK 03 - SHRNUT√ç\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìà Kompletn√≠ Dataset:\")\n",
    "print(f\"   Z√°znam≈Ø: {len(complete_df):,}\")\n",
    "print(f\"   Ticker≈Ø: {complete_df['ticker'].nunique()}\")\n",
    "print(f\"   Sektor≈Ø: {complete_df['sector'].nunique()}\")\n",
    "print(f\"   Obdob√≠: {complete_df['date'].min().strftime('%Y-%m')} ‚Üí {complete_df['date'].max().strftime('%Y-%m')}\")\n",
    "\n",
    "print(f\"\\nüìä Sloupce ({len(complete_df.columns)}):\")\n",
    "print(f\"   OHLCV: 5\")\n",
    "print(f\"   Technick√©: {len(FEATURE_COLS) - 5}\")\n",
    "print(f\"   Fundamenty: {len(TARGET_COLS)}\")\n",
    "\n",
    "print(f\"\\nüîÑ Zdroj dat:\")\n",
    "for source, count in source_counts.items():\n",
    "    pct = count / len(complete_df) * 100\n",
    "    print(f\"   {source.capitalize()}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset p≈ôipraven pro Notebook 04!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

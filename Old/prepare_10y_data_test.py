#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
TESTOVACÃ VERZE - PÅ™Ã­prava 10letÃ½ch OHLCV dat s technickÃ½mi indikÃ¡tory.
Stahuje pouze 10 firem z kaÅ¾dÃ©ho sektoru pro rychlÃ© testovÃ¡nÃ­.
"""

import os
import time
import pandas as pd
import numpy as np
import yfinance as yf
from typing import List, Dict

# === KONFIGURACE ===
START_DATE = "2015-01-01"
END_DATE = "2025-10-01"
DATA_DIR = "./data_10y_test"  # JinÃ¡ sloÅ¾ka pro test data

# PRO TESTOVÃNÃ: PoÄet firem na sektor
TEST_LIMIT = 10  # 10 firem/sektor = 30 firem celkem

# Sector mapping
SECTOR_BUCKET_MAP = {
    "Information Technology": "Technology",
    "Communication Services": "Technology",
    "Consumer Discretionary": "Consumer",
    "Consumer Staples": "Consumer",
    "Industrials": "Industrials",
    "Energy": "Industrials",
    "Materials": "Industrials",
}

def log(msg: str):
    print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def get_sp500_constituents() -> pd.DataFrame:
    """ZÃ­skat S&P 500 seznam z Wikipedie"""
    import io
    import requests

    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()
        tables = pd.read_html(io.StringIO(r.text))
        df = tables[0].copy()
        df = df.rename(columns={"Symbol": "ticker", "Security": "name", "GICS Sector": "sector"})
        df["ticker"] = df["ticker"].str.replace(".", "-", regex=False)
        return df[["ticker", "name", "sector"]]
    except Exception as e:
        log(f"âŒ Chyba pÅ™i stahovÃ¡nÃ­ S&P 500: {e}")
        return pd.DataFrame()

def filter_tickers_by_buckets(df: pd.DataFrame, target_buckets: List[str]) -> Dict[str, List[str]]:
    """Filtruje a rozdÄ›luje tickery podle target buckets"""
    df = df.copy()
    df["bucket"] = df["sector"].map(SECTOR_BUCKET_MAP)
    df = df[df["bucket"].isin(target_buckets)]
    
    result = {}
    for bucket in target_buckets:
        tickers = df[df["bucket"] == bucket]["ticker"].tolist()
        
        # OmezenÃ­ pro testovÃ¡nÃ­
        if TEST_LIMIT is not None and len(tickers) > TEST_LIMIT:
            tickers = tickers[:TEST_LIMIT]
        
        result[bucket] = tickers
    
    return result

def calculate_rsi(series: pd.Series, period: int = 14) -> pd.Series:
    """VypoÄÃ­tÃ¡ RSI indikÃ¡tor"""
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def calculate_macd(series: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:
    """VypoÄÃ­tÃ¡ MACD indikÃ¡tor"""
    ema_fast = series.ewm(span=fast, adjust=False).mean()
    ema_slow = series.ewm(span=slow, adjust=False).mean()
    macd = ema_fast - ema_slow
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    histogram = macd - signal_line
    
    return pd.DataFrame({
        'macd': macd,
        'macd_signal': signal_line,
        'macd_hist': histogram
    })

def download_and_process_ticker(ticker: str) -> pd.DataFrame:
    """
    StÃ¡hne DENNÃ data pro ticker, agreguje na MÄšSÃÄŒNÃ a pÅ™idÃ¡ technickÃ© indikÃ¡tory.
    """
    try:
        yf_ticker = yf.Ticker(ticker)
        
        # StaÅ¾enÃ­ dennÃ­ch dat
        hist = yf_ticker.history(start=START_DATE, end=END_DATE, interval="1d")
        
        if hist.empty or len(hist) < 20:
            return pd.DataFrame()
        
        # Agregace na mÄ›sÃ­ÄnÃ­ data
        monthly = hist.resample('ME').agg({
            'Open': 'first',
            'High': 'max',
            'Low': 'min',
            'Close': 'last',  # Adj Close (yfinance upravuje automaticky)
            'Volume': 'mean',
            'Dividends': 'sum',
            'Stock Splits': lambda x: 1 if x.sum() > 0 else 0
        })
        
        # PÅ™ejmenovÃ¡nÃ­ sloupcÅ¯
        monthly = monthly.rename(columns={
            'Open': 'open',
            'High': 'high',
            'Low': 'low',
            'Close': 'close',
            'Volume': 'volume',
            'Dividends': 'dividends',
            'Stock Splits': 'split_occurred'
        })
        
        # === FEATURE ENGINEERING ===
        
        # 1. Volatilita (normalizovanÃ½ range)
        monthly['volatility'] = (monthly['high'] - monthly['low']) / monthly['close']
        
        # 2. Returns (mÄ›sÃ­ÄnÃ­ % zmÄ›na)
        monthly['returns'] = monthly['close'].pct_change()
        
        # 3. RSI (14 period)
        monthly['rsi_14'] = calculate_rsi(monthly['close'], period=14)
        
        # 4. MACD
        macd_df = calculate_macd(monthly['close'])
        monthly['macd'] = macd_df['macd']
        monthly['macd_signal'] = macd_df['macd_signal']
        monthly['macd_hist'] = macd_df['macd_hist']
        
        # 5. Simple Moving Averages
        monthly['sma_3'] = monthly['close'].rolling(window=3).mean()
        monthly['sma_6'] = monthly['close'].rolling(window=6).mean()
        monthly['sma_12'] = monthly['close'].rolling(window=12).mean()
        
        # 6. Exponential Moving Averages
        monthly['ema_3'] = monthly['close'].ewm(span=3, adjust=False).mean()
        monthly['ema_6'] = monthly['close'].ewm(span=6, adjust=False).mean()
        monthly['ema_12'] = monthly['close'].ewm(span=12, adjust=False).mean()
        
        # 7. Volume change
        monthly['volume_change'] = monthly['volume'].pct_change()
        
        # Reset indexu a pÅ™idÃ¡nÃ­ tickeru
        monthly = monthly.reset_index()
        monthly.rename(columns={'Date': 'date'}, inplace=True)
        monthly['ticker'] = ticker
        
        return monthly
        
    except Exception as e:
        log(f"  âŒ {ticker}: {e}")
        return pd.DataFrame()

def main():
    log("=" * 80)
    log("ğŸ§ª TESTOVACÃ RUN - 10 FIREM/SEKTOR")
    log("=" * 80)
    
    ensure_dir(DATA_DIR)
    
    # 1. ZÃ­skat S&P 500 spoleÄnosti
    log("Stahuji seznam S&P 500...")
    sp500 = get_sp500_constituents()
    if sp500.empty:
        log("âŒ NepodaÅ™ilo se zÃ­skat S&P 500 data")
        return
    
    log(f"âœ“ ZÃ­skÃ¡no {len(sp500)} spoleÄnostÃ­")
    
    # 2. Filtrovat tickery podle sektorÅ¯
    target_buckets = ["Technology", "Consumer", "Industrials"]
    bucket_tickers = filter_tickers_by_buckets(sp500, target_buckets)
    
    ticker_counts = {b: len(t) for b, t in bucket_tickers.items()}
    log(f"âœ“ VybrÃ¡no {sum(ticker_counts.values())} tickerÅ¯: {ticker_counts}")
    log(f"âš  TESTOVACÃ REÅ½IM: {TEST_LIMIT} firem/sektor (celkem {sum(ticker_counts.values())} firem)")
    
    # 3. StahovÃ¡nÃ­ a zpracovÃ¡nÃ­ dat
    all_data = []
    total_tickers = sum(len(tickers) for tickers in bucket_tickers.values())
    processed = 0
    
    start_time = time.time()
    
    for bucket, tickers in bucket_tickers.items():
        log(f"\nğŸ“Š {bucket} ({len(tickers)} tickerÅ¯)...")
        
        for ticker in tickers:
            processed += 1
            log(f"  [{processed}/{total_tickers}] {ticker}...")
            
            df = download_and_process_ticker(ticker)
            if not df.empty:
                df['sector'] = bucket
                all_data.append(df)
    
    elapsed = time.time() - start_time
    log(f"\nâœ“ StaÅ¾eno za {elapsed:.1f}s ({elapsed/total_tickers:.1f}s/ticker)")
    
    # 4. SpojenÃ­ vÅ¡ech dat
    if not all_data:
        log("âŒ Å½Ã¡dnÃ¡ data k uloÅ¾enÃ­")
        return
    
    combined = pd.concat(all_data, ignore_index=True)
    log(f"âœ“ Celkem {len(combined)} zÃ¡znamÅ¯")
    
    # 5. UloÅ¾enÃ­
    # CelÃ½ dataset
    all_path = os.path.join(DATA_DIR, "all_sectors_full_10y.csv")
    combined.to_csv(all_path, index=False)
    log(f"âœ“ {all_path}")
    
    # Po sektorech
    for bucket in target_buckets:
        sector_df = combined[combined['sector'] == bucket].copy()
        if not sector_df.empty:
            sector_path = os.path.join(DATA_DIR, f"{bucket}_full_10y.csv")
            sector_df.to_csv(sector_path, index=False)
            
            n_months = sector_df['date'].nunique()
            n_tickers = sector_df['ticker'].nunique()
            log(f"âœ“ {bucket}_full_10y.csv ({n_months} mÄ›sÃ­cÅ¯ Ã— {n_tickers} tickerÅ¯)")
            
            # UloÅ¾enÃ­ seznamu tickerÅ¯
            ticker_list_path = os.path.join(DATA_DIR, f"{bucket}_tickers.txt")
            with open(ticker_list_path, 'w') as f:
                for t in sorted(sector_df['ticker'].unique()):
                    f.write(f"{t}\n")
            log(f"  â†’ {bucket}_tickers.txt")
    
    # 6. AnalÃ½za chybÄ›jÃ­cÃ­ch dat
    log("\n" + "=" * 80)
    log("ANALÃZA CHYBÄšJÃCÃCH DAT")
    log("=" * 80)
    
    missing_tickers = []
    for ticker in combined['ticker'].unique():
        ticker_df = combined[combined['ticker'] == ticker]
        missing_pct = ticker_df['close'].isna().sum() / len(ticker_df) * 100
        if missing_pct > 50:
            missing_tickers.append((ticker, missing_pct))
    
    if missing_tickers:
        log(f"âš  {len(missing_tickers)} tickerÅ¯ s >50% chybÄ›jÃ­cÃ­ch dat:")
        for ticker, pct in sorted(missing_tickers, key=lambda x: x[1], reverse=True):
            log(f"  â€¢ {ticker}: {pct:.1f}%")
    else:
        log("âœ“ VÅ¡echny tickery majÃ­ <50% chybÄ›jÃ­cÃ­ch dat")
    
    log("\nâœ… TEST HOTOVO!")
    log(f"â± CelkovÃ½ Äas: {elapsed/60:.2f} minut ({elapsed:.1f}s)")
    log(f"ğŸ“Š TestovacÃ­ data: {DATA_DIR}/")
    log(f"ğŸ” Zkontroluj vÃ½sledky pÅ™ed spuÅ¡tÄ›nÃ­m plnÃ©ho runu")

if __name__ == "__main__":
    main()
